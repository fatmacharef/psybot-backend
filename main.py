from fastapi import FastAPI
import requests
import os
from pydantic import BaseModel
from nltk.tokenize import word_tokenize
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from duckduckgo_search import DDGS
import nltk

# ğŸ“Œ TÃ©lÃ©charger les ressources nÃ©cessaires pour NLTK
nltk.download("punkt")

# ğŸ“Œ Charger le token Hugging Face depuis la variable dâ€™environnement
HF_TOKEN = os.getenv("HF_TOKEN")

# ğŸ“Œ URL de l'API Hugging Face pour ton modÃ¨le PsyBot
HF_MODEL_URL = "https://api-inference.huggingface.co/models/fatmata/psybot"

# ğŸ“Œ Initialisation de FastAPI
app = FastAPI()

# ğŸ“Œ Analyse des Ã©motions avec VADER
analyzer = SentimentIntensityAnalyzer()

# ğŸ“Œ Mots-clÃ©s pour la dÃ©tection des recherches
search_keywords = {
    "what", "who", "define", "explain", "is", "how", "causes", "symptoms",
    "treatment", "history", "types", "effects", "meaning", "scientific", "study", "research"
}

# ğŸ“Œ ModÃ¨le pour recevoir l'entrÃ©e utilisateur
class UserInput(BaseModel):
    user_input: str

# ğŸ“Œ Fonction pour gÃ©nÃ©rer une rÃ©ponse avec l'API Hugging Face
def generate_response(user_input):
    prompt = f"<|startoftext|><|user|> {user_input} <|bot|>"
    
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    payload = {"inputs": prompt, "parameters": {
        "max_new_tokens": 100,
        "do_sample": True,
        "temperature": 0.7,
        "top_k": 50,
        "top_p": 0.9,
        "repetition_penalty": 1.2
    }}

    response = requests.post(HF_MODEL_URL, headers=headers, json=payload)
    response_json = response.json()

    # ğŸ“Œ Extraire la rÃ©ponse correctement
    if isinstance(response_json, list) and len(response_json) > 0:
        generated_text = response_json[0]['generated_text']
        return generated_text.split("<|bot|>")[-1].strip()
    else:
        return "DÃ©solÃ©, je ne peux pas rÃ©pondre pour le moment."

# ğŸ“Œ Fonction de recherche avec DuckDuckGo
def search_duckduckgo(query, max_results=3):
    """Recherche des informations sur DuckDuckGo et retourne une liste de rÃ©sultats."""
    search_results = list(DDGS().text(query, max_results=max_results))
    if search_results:
        return [result["body"] for result in search_results]
    return ["Je n'ai pas trouvÃ© d'informations sur ce sujet."]

# ğŸ“Œ Fonction de classification et rÃ©ponse
def classify_and_respond(text):
    tokens = set(word_tokenize(text.lower()))

    # ğŸ”¹ VÃ©rifier si c'est une recherche
    if tokens.intersection(search_keywords) or text.endswith('?'):
        return search_duckduckgo(text)
    
    # ğŸ”¹ Analyse du sentiment avec VADER
    vader_score = analyzer.polarity_scores(text)["compound"]

    # ğŸ”¹ Bloquer les messages violents
    violent_keywords = {"punch", "hit", "hurt", "kill", "destroy", "break", "explode", "attack"}
    if any(word in text.lower() for word in violent_keywords):
        return ["ğŸ”´ Non AcceptÃ©: Essayez de vous calmer. La violence ne rÃ©sout rien."]

    # ğŸ”¹ Si la requÃªte est acceptable, utiliser GPT
    response = generate_response(text)
    return [f"ğŸŸ¢ AcceptÃ©: {response}"]

# ğŸ“Œ Endpoint principal de l'API
@app.post("/chat/")
async def chat_with_bot(user_input: UserInput):
    response = classify_and_respond(user_input.user_input)
    return {"response": response}
