from fastapi import FastAPI
import requests
from pydantic import BaseModel
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from transformers import AutoTokenizer
from duckduckgo_search import DDGS
from fastapi.middleware.cors import CORSMiddleware  # âœ… Ajout CORS

# ğŸ“Œ Charger le tokenizer de PsyBot
tokenizer = AutoTokenizer.from_pretrained("fatmata/psybot")

# ğŸ“Œ Initialisation de FastAPI
app = FastAPI()

# âœ… Ajouter CORS pour autoriser les requÃªtes du frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ğŸš¨ Mettre "*" pour tester, mais mieux de restreindre plus tard
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“Œ Initialisation de l'analyseur VADER
analyzer = SentimentIntensityAnalyzer()

# ğŸ“Œ Liste des mots-clÃ©s pour dÃ©tecter une recherche
search_keywords = {
    "what", "who", "define", "explain", "is", "how", "causes", "symptoms",
    "treatment", "history", "types", "effects", "meaning", "scientific", "study", "research"
}

# ğŸ“Œ Liste des mots-clÃ©s violents
violent_keywords = {"punch", "hit", "hurt", "kill", "destroy", "break", "explode", "attack"}

# ğŸ“Œ ModÃ¨le pour recevoir l'entrÃ©e utilisateur
class UserInput(BaseModel):
    user_input: str

# ğŸ“Œ Fonction pour tokenizer le texte
def tokenize_text(text):
    return set(tokenizer.tokenize(text.lower()))

# ğŸ“Œ Fonction pour gÃ©nÃ©rer une rÃ©ponse avec l'API Hugging Face Spaces
def generate_response(user_input):
    HF_SPACE_URL = "https://fatmata-psybot-api.hf.space/generate"  # VÃ©rifie bien cette URL

    prompt = f"<|startoftext|><|user|> {user_input} <|bot|>"
    payload = {
        "prompt": prompt,
        "max_new_tokens": 100,
        "pad_token_id": tokenizer.eos_token_id,
        "eos_token_id": tokenizer.eos_token_id,
        "do_sample": True,
        "temperature": 0.7,
        "top_k": 50,
        "top_p": 0.9,
        "repetition_penalty": 1.2
    }

    headers = {"Content-Type": "application/json"}

    try:
        print(f"ğŸš€ Envoi de la requÃªte Ã  {HF_SPACE_URL}...")

        response = requests.post(HF_SPACE_URL, json=payload, headers=headers, timeout=30)

        print(f"ğŸ“¡ Statut HTTP: {response.status_code}")
        print(f"ğŸ“¡ RÃ©ponse brute de HF: {response.text}")

        if response.status_code != 200:
            try:
                error_detail = response.json().get("detail", "Impossible d'obtenir une rÃ©ponse.")
            except Exception:
                error_detail = "Impossible d'obtenir une rÃ©ponse."
            return f"ğŸš¨ Erreur {response.status_code} : {error_detail}"

        response_json = response.json()

        if isinstance(response_json, dict) and "response" in response_json:
            return response_json["response"]

        return "DÃ©solÃ©, je ne peux pas rÃ©pondre pour le moment."

    except requests.exceptions.Timeout:
        return "ğŸ›‘ Erreur : Temps de rÃ©ponse trop long. RÃ©essaie plus tard."
    except requests.exceptions.RequestException as e:
        return f"ğŸ›‘ Erreur de connexion Ã  Hugging Face : {str(e)}"

# ğŸ“Œ Fonction de recherche avec DuckDuckGo
def search_duckduckgo(query, max_results=3):
    try:
        search_results = list(DDGS().text(query, max_results=max_results))
        return [result["body"] for result in search_results if "body" in result] or ["Je n'ai pas trouvÃ© d'informations sur ce sujet."]
    except Exception as e:
        return [f"Erreur de recherche : {str(e)}"]

# ğŸ“Œ Fonction de classification et rÃ©ponse
def classify_and_respond(text):
    print(f"ğŸ” Message reÃ§u : {text}")

    try:
        tokens = tokenize_text(text)
        print(f"âœ… Tokens : {tokens}")

        if tokens.intersection(search_keywords) or text.endswith('?'):
            return search_duckduckgo(text)

        if any(word in text.lower().split() for word in violent_keywords):
            return ["ğŸ”´ Non AcceptÃ©: Essayez de vous calmer. La violence ne rÃ©sout rien."]

        vader_score = analyzer.polarity_scores(text)["compound"]
        print(f"ğŸ§  Score VADER : {vader_score}")

        response = generate_response(text)
        print(f"ğŸ¤– RÃ©ponse GPT : {response}")
        return [f"ğŸŸ¢ AcceptÃ©: {response}"]

    except Exception as e:
        print(f"âŒ Erreur classification : {e}")
        return ["âš ï¸ Une erreur est survenue dans la classification du message."]

# ğŸ“Œ Endpoint API
@app.post("/chat/")
async def chat_with_bot(user_input: UserInput):
    print(f"ğŸ“¥ RequÃªte reÃ§ue du frontend: {user_input.user_input}")
    return {"response": classify_and_respond(user_input.user_input)}

@app.get("/")
async def home():
    return {"message": "PsyBot API is running!"}
